{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN-ptan2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qne_ya16_VKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import gym\n",
        " import torch\n",
        " import torch.nn as n\n",
        " import torch.nn.functional as f\n",
        " import numpy as np\n",
        " import matplotlib.pyplot as plt\n",
        " import torch.optim as op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPETHQAiAM8a",
        "colab_type": "code",
        "outputId": "6f28f85e-aead-44b7-9c47-4f7290beb507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install ptan"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ptan\n",
            "  Downloading https://files.pythonhosted.org/packages/91/cb/57f6d86625f2b24c008b0524ca29559683aa75d00afa38b6b44d7fcad25b/ptan-0.6.tar.gz\n",
            "Collecting torch==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n",
            "\u001b[K     |████████████████████████████████| 773.1MB 20kB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from ptan) (0.17.1)\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.6/dist-packages (from ptan) (0.2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ptan) (1.18.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from ptan) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym->ptan) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->ptan) (0.16.0)\n",
            "Building wheels for collected packages: ptan\n",
            "  Building wheel for ptan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ptan: filename=ptan-0.6-cp36-none-any.whl size=23502 sha256=ebc3958bfe6cba5d97db799d8d529211ed1ef48271f7c8a31fbd6c31c907e169\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/4b/2f/9a45fd39b0a614a2716bc6128a7f1adb4647f323a2d90783f2\n",
            "Successfully built ptan\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, ptan\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed ptan-0.6 torch-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWm3EmMYAPCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ptan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_lw42slAP6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env=gym.make(\"CartPole-v0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkaWGIqhASvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obsdim=env.observation_space.shape[0]\n",
        "nactions=env.action_space.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBuiCybPAsdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(n.Module):      # gives out action values given state x for each action\n",
        "  def __init__(self,obsdim,nactions):\n",
        "    super().__init__()\n",
        "    self.obsdim=obsdim\n",
        "    self.nact=nactions\n",
        "    self.fc1=n.Linear(obsdim,128)\n",
        "    self.fc2=n.Linear(128,nactions)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x=x.float()\n",
        "    out=f.relu(self.fc1(x))\n",
        "    return self.fc2(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPMYiM_IBYTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=net(obsdim,nactions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh0dmjAeBkVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# experiment source for getting s a r nexts\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y1Cf9VACo-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eps=0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fw9e-xxMBzaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actionselector=ptan.actions.EpsilonGreedyActionSelector(epsilon=eps)\n",
        "agent=ptan.agent.DQNAgent(model,actionselector,device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq0Il3Q3ClIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "expsource=ptan.experience.ExperienceSourceFirstLast(env,agent,gamma=0.99,steps_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9IPqCC8DTZJ",
        "colab_type": "code",
        "outputId": "7709f4fc-7055-40a3-ab56-b392040e3396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "count=0\n",
        "for e in expsource:\n",
        "  print(e.state,\"--\",e.last_state,\"--\",e.reward,\"--\",expsource.pop_total_rewards())\n",
        "  count+=1\n",
        "  if count==20:\n",
        "    break\n",
        "\n",
        "# Before appending we should check pop total rewards if it is non zero whatever states actions rewards last states in previous list can be\n",
        "# used for a single episode"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03485613 0.02608345 0.02001394 0.04839476] -- [ 0.0353778   0.22091278  0.02098183 -0.23790701] -- 1.0 -- []\n",
            "[ 0.0353778   0.22091278  0.02098183 -0.23790701] -- [ 0.03979605  0.4157288   0.01622369 -0.5238985 ] -- 1.0 -- []\n",
            "[ 0.03979605  0.4157288   0.01622369 -0.5238985 ] -- [ 0.04811063  0.61061871  0.00574572 -0.81142534] -- 1.0 -- []\n",
            "[ 0.04811063  0.61061871  0.00574572 -0.81142534] -- [ 0.060323    0.80566148 -0.01048278 -1.10229543] -- 1.0 -- []\n",
            "[ 0.060323    0.80566148 -0.01048278 -1.10229543] -- [ 0.07643623  1.00091976 -0.03252869 -1.39824865] -- 1.0 -- []\n",
            "[ 0.07643623  1.00091976 -0.03252869 -1.39824865] -- [ 0.09645463  1.19643073 -0.06049367 -1.7009217 ] -- 1.0 -- []\n",
            "[ 0.09645463  1.19643073 -0.06049367 -1.7009217 ] -- [ 0.12038324  1.39219513 -0.0945121  -2.01180547] -- 1.0 -- []\n",
            "[ 0.12038324  1.39219513 -0.0945121  -2.01180547] -- [ 0.14822715  1.58816412 -0.13474821 -2.33219227] -- 1.0 -- []\n",
            "[ 0.14822715  1.58816412 -0.13474821 -2.33219227] -- [ 0.17999043  1.78422347 -0.18139206 -2.66311163] -- 1.0 -- []\n",
            "[ 0.17999043  1.78422347 -0.18139206 -2.66311163] -- None -- 1.0 -- []\n",
            "[-0.03414603  0.01357536  0.02830854 -0.03283273] -- [-0.03387452  0.20828015  0.02765188 -0.31645131] -- 1.0 -- [10.0]\n",
            "[-0.03387452  0.20828015  0.02765188 -0.31645131] -- [-0.02970891  0.40299755  0.02132286 -0.60028713] -- 1.0 -- []\n",
            "[-0.02970891  0.40299755  0.02132286 -0.60028713] -- [-0.02164896  0.59781481  0.00931711 -0.88617815] -- 1.0 -- []\n",
            "[-0.02164896  0.59781481  0.00931711 -0.88617815] -- [-0.00969267  0.79280904 -0.00840645 -1.17591762] -- 1.0 -- []\n",
            "[-0.00969267  0.79280904 -0.00840645 -1.17591762] -- [ 0.00616351  0.9880392  -0.0319248  -1.47122397] -- 1.0 -- []\n",
            "[ 0.00616351  0.9880392  -0.0319248  -1.47122397] -- [ 0.0259243   1.18353671 -0.06134928 -1.77370511] -- 1.0 -- []\n",
            "[ 0.0259243   1.18353671 -0.06134928 -1.77370511] -- [ 0.04959503  1.37929427 -0.09682338 -2.08481441] -- 1.0 -- []\n",
            "[ 0.04959503  1.37929427 -0.09682338 -2.08481441] -- [ 0.07718092  1.57525222 -0.13851967 -2.40579623] -- 1.0 -- []\n",
            "[ 0.07718092  1.57525222 -0.13851967 -2.40579623] -- [ 0.10868596  1.77128228 -0.1866356  -2.73761949] -- 1.0 -- []\n",
            "[ 0.10868596  1.77128228 -0.1866356  -2.73761949] -- None -- 1.0 -- []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vsjDhFfDxh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffer=ptan.experience.ExperienceReplayBuffer(expsource,10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLf8LufJFC3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer=op.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb-1JEdxFnE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tgtmodel=ptan.agent.TargetNet(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMAQF6C9EvGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "stopreward=500\n",
        "gamma=0.99\n",
        "batchsize=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk2W-EhuGCoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class rewardtracker:\n",
        "  def __init__(self,stopreward):\n",
        "    self.stopreward=stopreward\n",
        "    self.totalreward=[]\n",
        "  \n",
        "  def reward(self,frame,reward1):\n",
        "    self.totalreward.append(reward1)\n",
        "    meanreward=np.mean(self.totalreward[-100:])\n",
        "    if meanreward>stopreward:\n",
        "      return True\n",
        "    return False\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhrb-XZOHrfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpackbatch(batch):\n",
        "  states,actions,rewards,dones,nextstate=[],[],[],[],[]\n",
        "\n",
        "  for st in batch:\n",
        "    states.append(np.array(st.state))\n",
        "    actions.append(np.array(st.action))\n",
        "    rewards.append(np.array(st.reward))\n",
        "    dones.append(np.array(st.last_state is None))\n",
        "    if st.last_state is None:\n",
        "\n",
        "      nextstate.append(np.array(st.state))\n",
        "    else:\n",
        "      nextstate.append(np.array(st.last_state))\n",
        "    return np.array(states),np.array(actions),np.array(rewards),np.array(dones),np.array(nextstate)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-vGIgsJhXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcloss(batch,net,tgtnet,gamma,device):\n",
        "  batchs,batchac,batchrew,batchdone,batchns=unpackbatch(batch)\n",
        "  batchs=torch.tensor(batchs).to(device)\n",
        "  batchac=torch.tensor(batchac).to(device)\n",
        "  batchrew=torch.tensor(batchrew).to(device)\n",
        "  batchdone=torch.BoolTensor(batchdone).to(device)\n",
        "  batchns=torch.tensor(batchns).to(device)\n",
        "  actionqval=net(batchs).gather(1,batchac.unsqueeze(-1)).squeeze(-1)\n",
        "  nextstateactqval=tgtnet(batchns).max(1)[0]\n",
        "  nextstateactqval[batchdone]=0.0\n",
        "\n",
        "  return n.MSELoss()(actionqval,(batchrew+gamma*nextstateactqval))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Biwu7FU4FDW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rt=rewardtracker(stopreward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWWbBjf6RWaK",
        "colab_type": "code",
        "outputId": "79ff4b82-fed6-4e0b-c107-eaf2319bc498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "tgtmodel.target_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "net(\n",
              "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Lkxht5RX74",
        "colab_type": "code",
        "outputId": "9e77a49b-3b89-458e-bf51-4ba3c1d307cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "tgtmodel.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "net(\n",
              "  (fc1): Linear(in_features=4, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mLRsvboGj2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device1=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb7T6iRbDLEo",
        "colab_type": "code",
        "outputId": "a64b185b-8cba-4028-f7aa-682dc1dc8884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "frameidx=0\n",
        "rew=[]\n",
        "while True:\n",
        "  frameidx+=1\n",
        "  buffer.populate(1)\n",
        "  newrewards=expsource.pop_total_rewards()\n",
        "  if newrewards:\n",
        "    rew.append(newrewards[0])\n",
        "  if newrewards:\n",
        "    if rt.reward(frameidx,newrewards[0]):\n",
        "      break\n",
        "  \n",
        "  if len(buffer)<5000:\n",
        "    continue\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  batch=buffer.sample(batchsize)\n",
        "  lossv=calcloss(batch,model,tgtmodel.target_model,gamma=gamma,device=device1)\n",
        "  lossv.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if frameidx%5000==0:\n",
        "    print(lossv.item())\n",
        "    print(np.mean(rew))\n",
        "  if frameidx%1000==0:\n",
        "    tgtmodel.sync()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0185098578367615\n",
            "113.4888888888889\n",
            "0.42069879273185506\n",
            "125.1604938271605\n",
            "0.361996779742185\n",
            "67.82352941176471\n",
            "0.06158593205327634\n",
            "75.77735849056604\n",
            "0.21776935161688016\n",
            "82.16339869281046\n",
            "0.1046582130366005\n",
            "88.54867256637168\n",
            "0.11551970388973132\n",
            "94.37903225806451\n",
            "0.008739065902773291\n",
            "99.82835820895522\n",
            "0.08628278743708506\n",
            "104.76566125290023\n",
            "0.055246803909540176\n",
            "109.43326039387308\n",
            "0.32084196858340874\n",
            "114.19047619047619\n",
            "0.11596095026470721\n",
            "118.20275590551181\n",
            "1.4040022427216172\n",
            "120.37892791127541\n",
            "0.10520686605013907\n",
            "122.4493006993007\n",
            "0.009853749128524214\n",
            "122.28175895765472\n",
            "349.71827770177333\n",
            "108.76662143826323\n",
            "5.800434482807759\n",
            "109.25064267352185\n",
            "0.0414583683013916\n",
            "109.77344701583435\n",
            "0.46495642891386524\n",
            "109.78521939953811\n",
            "0.06269088038243353\n",
            "111.93064876957494\n",
            "9.178581042448059\n",
            "114.14115092290989\n",
            "0.04531592153944075\n",
            "116.32101372756071\n",
            "0.031635629071388394\n",
            "118.47325102880659\n",
            "0.2787919277907349\n",
            "120.51755265797392\n",
            "0.24817229807376862\n",
            "122.2314453125\n",
            "0.6223668116726913\n",
            "123.57549857549857\n",
            "0.3708452429273166\n",
            "125.04162812210916\n",
            "0.002544754184782505\n",
            "125.78885893980234\n",
            "0.2130123341921717\n",
            "126.44860627177701\n",
            "0.01165942574152723\n",
            "127.79404255319149\n",
            "0.0007581478566862643\n",
            "129.04159733777038\n",
            "0.004856262588873506\n",
            "130.39934800325997\n",
            "0.20150969759561121\n",
            "131.57655502392345\n",
            "0.25107690185541287\n",
            "132.92421875\n",
            "0.03958785912254825\n",
            "134.17394636015325\n",
            "0.04820937995100394\n",
            "134.28859060402684\n",
            "0.007134340761695057\n",
            "134.15797101449274\n",
            "1.3807397484779358\n",
            "133.8718309859155\n",
            "0.19305870408425108\n",
            "132.01692620176033\n",
            "0.19717686832882464\n",
            "133.07717897538257\n",
            "0.45217498228885233\n",
            "134.0981033355134\n",
            "2.4835241772816516\n",
            "135.15830115830116\n",
            "0.15076943882741034\n",
            "136.10632911392406\n",
            "8.60024356842041\n",
            "137.0024906600249\n",
            "0.004408776818308979\n",
            "137.96017156862746\n",
            "0.08846576238283888\n",
            "138.87447193723597\n",
            "0.18344652611995116\n",
            "139.71301247771837\n",
            "0.001989969110582024\n",
            "140.48917495611468\n",
            "5.939869801206669\n",
            "140.70091848450056\n",
            "98.62627150700428\n",
            "139.60915689558905\n",
            "13.551500454137567\n",
            "137.6084142394822\n",
            "0.00427605357253924\n",
            "138.16622411046203\n",
            "0.07062961556948721\n",
            "138.7216117216117\n",
            "2.209715638309717\n",
            "139.03501544799175\n",
            "0.026190475560724735\n",
            "139.51217038539554\n",
            "0.1066171566490084\n",
            "140.10455227613807\n",
            "0.13879990577697754\n",
            "140.44630541871922\n",
            "0.25246270024217665\n",
            "140.98299319727892\n",
            "0.01710421429015696\n",
            "141.66874699951993\n",
            "0.18224434738294804\n",
            "142.2568720379147\n",
            "0.04986841813661158\n",
            "142.76789892372486\n",
            "0.0028938870527781546\n",
            "143.42969472710453\n",
            "0.38188160420395434\n",
            "144.07178783721994\n",
            "0.13050839776406065\n",
            "144.66877541798465\n",
            "0.1545431865961291\n",
            "144.96743978590544\n",
            "0.015705211320891976\n",
            "145.48038783605114\n",
            "4.333456390537322\n",
            "145.9512195121951\n",
            "0.020738487379276194\n",
            "146.4829814735028\n",
            "1.0012134416174376\n",
            "146.87063829787235\n",
            "0.36352236807579175\n",
            "147.28270929743374\n",
            "0.11061998293735087\n",
            "147.66555740432614\n",
            "0.2808420989313163\n",
            "148.05879934210526\n",
            "9.077666227298323\n",
            "148.4979658258747\n",
            "0.47929887945065275\n",
            "148.7159501807955\n",
            "0.022386161203030497\n",
            "149.05802861685214\n",
            "0.2529305965290405\n",
            "149.53186467348544\n",
            "0.021506874123588204\n",
            "149.696734059098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-52bdb9510f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mlossv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalcloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgtmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mlossv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         raise RuntimeError(trim(r\"\"\"reinforce() was removed.\n\u001b[1;32m    197\u001b[0m             \u001b[0mUse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3f-jK16GdTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}